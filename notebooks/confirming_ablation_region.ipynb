{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirming the Anatomical Region of the Ablation Using Freesurfer LUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After annotating the ablation region of the post surgical MRI with Seg3D, we use Slicer to reorient the MRI from RAS to freesurfer (FS) space. Then on the mask, we overlay the Desikan-Killiany atlas provided by Freesurfer, matching each voxel to its corresponding brain region in the atlas. Compare the resulting list of brain regions to what was clinically reported will allow us to confirm that the mask was mapped to the correct space. \n",
    "\n",
    "We will us la02 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freesurfer's lookup table (LUT) assigns a number to a certain brain region. The full table can be found here:\n",
    "https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lookup table for freesurfer labels\n"
     ]
    }
   ],
   "source": [
    "# get labels using Freesurfer's lookup table (LUT)\n",
    "fs_lut_fpath = \"C:\\\\Users\\\\d0156\\\\Dropbox\\\\bids_layout_data\\\\sub-la02\\\\FreeSurferColorLUT.txt\"\n",
    "fid = open(fs_lut_fpath)\n",
    "LUT = fid.readlines()\n",
    "fid.close()\n",
    "\n",
    "# make dictionary of labels\n",
    "LUT = [row.split() for row in LUT]\n",
    "lab = {}\n",
    "for row in LUT:\n",
    "    if (\n",
    "        len(row) > 1 and row[0][0] is not \"#\" and row[0][0] is not \"\\\\\"\n",
    "    ):\n",
    "        lname = row[1]\n",
    "        lab[np.int(row[0])] = lname\n",
    "\n",
    "print(\"Loading lookup table for freesurfer labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freesurfer provides three different types of atlases: Desikan-Killiany, DKT, and Destrieux. The three are trained in different ways, but in general, an atlas is a model of the cortical surface based on probabilistic information estimated from a manually labeled training set. For more information, visit\n",
    "https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading atlas\n"
     ]
    }
   ],
   "source": [
    "# assuming atlas type is desikan-killiany\n",
    "depth_atlas_suffix = \"\"\n",
    "mri_dir = \"C:\\\\Users\\\\d0156\\\\Dropbox\\\\bids_layout_data\\\\la02\\\\mri\"\n",
    "\n",
    "# load in ASEG image file from atlas\n",
    "aseg_fpath = os.path.join(mri_dir, \"aparc%s+aseg.mgz\" % (depth_atlas_suffix))\n",
    "depth_atlas_img = nb.freesurfer.load(aseg_fpath)\n",
    "aparc_dat = depth_atlas_img.get_fdata()\n",
    "\n",
    "print(\"Loading atlas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After annotating the ablation in Seg3D and mapping the mask to FS space using Slicer, we index the annotated voxels of the mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mask\n",
      "Loading mask index\n"
     ]
    }
   ],
   "source": [
    "# load mask image\n",
    "mask_dir = \"C:\\\\Users\\\\d0156\\\\Dropbox\\\\bids_layout_data\\\\sub-la02\\\\test\"\n",
    "mask_fpath = os.path.join(mask_dir, \"sub-la02_ses-postsurgery_proc-slicer.nii\")\n",
    "mask_img = nb.load(mask_fpath)\n",
    "mask_data = mask_img.get_fdata()\n",
    "\n",
    "print(\"Loading mask\")\n",
    "\n",
    "# determine where mask is\n",
    "mask_indx = np.argwhere(mask_data)\n",
    "\n",
    "print(\"Loading mask index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overlay the annotated voxels with the atlas and the LUT, which gives us a list of brain regions within the mask. This should be similar to what was reported clinically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading brain regions in mask\n",
      "Brain regions in mask: \n",
      "['ctx-lh-superiorfrontal', 'Left-Cerebral-White-Matter', 'WM-hypointensities', 'ctx-lh-rostralmiddlefrontal']\n"
     ]
    }
   ],
   "source": [
    "# determine list of brain regions in mask\n",
    "aparc_indx = []\n",
    "for i in range(len(mask_indx)):\n",
    "    aparc_indx.append(aparc_dat[mask_indx[i][0], mask_indx[i][1], mask_indx[i][2]])\n",
    "\n",
    "regions = []\n",
    "for i in range(len(aparc_indx)):\n",
    "    if (aparc_indx[i] != 0) and (lab[aparc_indx[i]] not in regions):\n",
    "        regions.append(lab[aparc_indx[i]])\n",
    "\n",
    "print(\"Loading brain regions in mask\")\n",
    "\n",
    "print(\"Brain regions in mask: \")\n",
    "print(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _from_tsv(fname, dtypes=None):\n",
    "    \"\"\"Read a tsv file into an OrderedDict.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Path to the file being loaded.\n",
    "    dtypes : list, optional\n",
    "        List of types to cast the values loaded as. This is specified column by\n",
    "        column.\n",
    "        Defaults to None. In this case all the data is loaded as strings.\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict : collections.OrderedDict\n",
    "        Keys are the column names, and values are the column data.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(fname, dtype=str, delimiter='\\t',\n",
    "                      comments=None, encoding='utf-8')\n",
    "    column_names = data[0, :]\n",
    "    info = data[1:, :]\n",
    "    data_dict = collections.OrderedDict()\n",
    "    if dtypes is None:\n",
    "        dtypes = [str] * info.shape[1]\n",
    "    if not isinstance(dtypes, (list, tuple)):\n",
    "        dtypes = [dtypes] * info.shape[1]\n",
    "    if not len(dtypes) == info.shape[1]:\n",
    "        raise ValueError('dtypes length mismatch. Provided: {0}, '\n",
    "                         'Expected: {1}'.format(len(dtypes), info.shape[1]))\n",
    "    for i, name in enumerate(column_names):\n",
    "        data_dict[name] = info[:, i].astype(dtypes[i]).tolist()\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.99999940e-01  0.00000000e+00  0.00000000e+00  1.26817993e+02]\n",
      " [ 0.00000000e+00 -1.49011612e-08  1.00000000e+00 -1.21573318e+02]\n",
      " [ 0.00000000e+00 -1.00000000e+00  0.00000000e+00  1.59645630e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[-9.99999932e-01  2.61643042e-04 -2.61643042e-04  1.26817993e+02]\n",
      " [-2.61643042e-04  3.42285418e-08  9.99999966e-01 -1.21573318e+02]\n",
      " [-2.61643042e-04 -9.99999966e-01 -3.42285418e-08  1.59645630e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "pret1_fpath = \"C:\\\\Users\\\\d0156\\\\Johns Hopkins\\\\Adam Li - epilepsy_bids\\\\sub-la02\\\\ses-presurgery\\\\anat\\\\sub-la02_ses-presurgery_space-fs_T1w.nii\"\n",
    "pret1_img = nb.load(pret1_fpath)\n",
    "pret1_aff = pret1_img.affine\n",
    "print(pret1_aff)\n",
    "\n",
    "mask_aff = mask_img.affine\n",
    "print(mask_aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"L'4\", \"L'5\"]\n",
      "['Left-Cerebral-White-Matter', 'ctx-lh-superiorfrontal']\n"
     ]
    }
   ],
   "source": [
    "pre = _from_tsv(\"C:\\\\Users\\\\d0156\\\\Johns Hopkins\\\\Adam Li - epilepsy_bids\\\\sub-la02\\\\ses-presurgery\\\\ieeg\\\\sub-la02_ses-presurgery_acq-seeg_space-fs_electrodes.tsv\")\n",
    "\n",
    "keys = list(pre.keys())\n",
    "values = list(pre.values())\n",
    "coords = [[] for c in range(len(values[0]))]\n",
    "\n",
    "for i in range(len(values[0])):\n",
    "    for j in range(len(keys)):\n",
    "        coords[i].append(values[j][i])\n",
    "\n",
    "elec_coords = np.zeros((len(coords), 3))\n",
    "\n",
    "for i in range(len(coords)):\n",
    "    for j in range(3):\n",
    "        elec_coords[i][j] = float(coords[i][j+1])\n",
    "\n",
    "### comparing voxels\n",
    "elec_vox = np.floor(nb.affines.apply_affine(np.linalg.inv(pret1_aff), elec_coords))\n",
    "\n",
    "elecs = []\n",
    "elecs_name = []\n",
    "\n",
    "for i in range(len(mask_indx)):\n",
    "    for j in range(len(elec_vox)):\n",
    "        if (np.abs(elec_vox[j][0] - mask_indx[i][0]) <= 3) & (np.abs(elec_vox[j][1] - mask_indx[i][1]) <= 3) \\\n",
    "            & (np.abs(elec_vox[j][2] - mask_indx[i][2]) <= 3):\n",
    "            if (coords[j][0] not in elecs):\n",
    "                elecs.append(coords[j][0])\n",
    "                elecs_name.append(coords[j][5])\n",
    "\n",
    "print(elecs)\n",
    "print(elecs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"G'6\", \"L'4\", \"L'5\"]\n",
      "['Left-Cerebral-White-Matter', 'Left-Cerebral-White-Matter', 'ctx-lh-superiorfrontal']\n"
     ]
    }
   ],
   "source": [
    "### comparing xyz coordinates\n",
    "\n",
    "mask_coords = nb.affines.apply_affine(mask_aff, mask_indx)\n",
    "elecs = []\n",
    "elecs_name = []\n",
    "\n",
    "\n",
    "for i in range(len(mask_coords)):\n",
    "    for j in range(len(elec_coords)):\n",
    "        if (np.abs(elec_coords[j][0] - mask_coords[i][0]) <= 4) & (np.abs(elec_coords[j][1] - mask_coords[i][1]) <= 4) \\\n",
    "            & (np.abs(elec_coords[j][2] - mask_coords[i][2]) <= 4):\n",
    "            if (coords[j][0] not in elecs):\n",
    "                elecs.append(coords[j][0])\n",
    "                elecs_name.append(coords[j][5])\n",
    "\n",
    "print(elecs)\n",
    "print(elecs_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
